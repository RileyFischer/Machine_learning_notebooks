{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vfwQ6YEhluba"},"outputs":[],"source":["# a) Load data\n","from google.colab import drive\n","import numpy as np\n","\n","drive.mount('/content/drive')\n","with open('/content/drive/My Drive/Colab Notebooks/data/iris.csv', 'r') as f: \n","  tmp = np.genfromtxt(f,delimiter=',')\n","X = tmp[:,:-1]\n","y = tmp[:,-1] "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"xPdGW-5IydHF","executionInfo":{"status":"ok","timestamp":1662943653740,"user_tz":300,"elapsed":124,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"outputs":[],"source":["# for easier reading np\n","np.set_printoptions(precision=3,suppress=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ga08Oc2ZnwqK"},"outputs":[],"source":["# b) number of samples, features dimension, the number of classes\n","\n","label, labelCount = np.unique(y,return_counts=True)\n","\n","print('num of samples: ', X.shape[0])\n","print('num of feature dimensions: ', X.shape[1])\n","print('num of classes:', len(label))\n","for i in range(len(label)):\n","  print('class %i has %i samples'%(label[i],labelCount[i]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZpvsgo2oXIb"},"outputs":[],"source":["# c) check nan, data imputation\n","from sklearn.impute import KNNImputer\n","\n","if np.sum(np.isnan(X)):\n","  print('Total of NaN before imputation:', np.sum(np.isnan(X)))\n","  imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n","  X1 = imputer.fit_transform(X)\n","  print('Total of NaN after imputation:', np.sum(np.isnan(X1)))\n","else:\n","  X1 = X\n","  print('no NaN')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Ue36ENusGef"},"outputs":[],"source":["# d) partition 80/20\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X1, y, train_size=0.8, shuffle = True, stratify = y);\n","\n","print('training data size: ', X_train.shape[0])\n","print('testing data size: ', X_test.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnkQ2QfWvO44"},"outputs":[],"source":["# e) standardize\n","from sklearn.preprocessing import StandardScaler\n","\n","scalerS = StandardScaler()\n","X_train_standardized = scalerS.fit_transform(X_train)\n","print('mean training data in each dimension, after standardization:', np.mean(X_train_standardized, axis=0))\n","print('std training data in each dimension, after standardization:', np.std(X_train_standardized, axis=0),'\\n')\n","\n","X_test_standardized = scalerS.transform(X_test)\n","print('mean testing data in each dimension, after standardization:', np.mean(X_test_standardized, axis=0))\n","print('std testing data in each dimension, after standardization:', np.std(X_test_standardized, axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhMyvX7TxO5S"},"outputs":[],"source":["# f) k fold\n","from sklearn.model_selection import KFold\n","\n","kf = KFold(n_splits=3,shuffle=True, random_state=1)\n","for i,(train_index, test_index) in enumerate(kf.split(X_train_standardized)):\n","  print('partition: ',i)\n","  print('training samples\\' class distribution: ', np.unique(y_train[train_index],return_counts=True)[1])\n","  print('validation samples\\' class distribution: ', np.unique(y_train[test_index],return_counts=True)[1], '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EqtiN5sX2ER7"},"outputs":[],"source":["drive.flush_and_unmount()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVTCY0X92lMW"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}