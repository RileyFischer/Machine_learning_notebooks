{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"717a35ac","executionInfo":{"status":"ok","timestamp":1666549341350,"user_tz":300,"elapsed":5883,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["# part of the code also refers to:\n","# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n","# !pip install d2l==0.17.0\n","import tensorflow as tf\n","import numpy as np\n","from google.colab import drive\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split"],"id":"717a35ac","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"71cfbd08","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6b425965-90f4-456f-8b89-c0d1dc565080","executionInfo":{"status":"ok","timestamp":1666549359448,"user_tz":300,"elapsed":18107,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["# import data\n","drive.mount('/content/drive')\n","with open('/content/drive/My Drive/Colab Notebooks/data/iris.csv', 'r') as f: \n","  data = np.genfromtxt(f, dtype='f4', delimiter=',')\n","X = data[:,:4]\n","# y = [data[:,4] == 1, data[:,4] == 2, data[:,4] == 3]\n","y = data[:,4]"],"id":"71cfbd08","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"7501ce39","executionInfo":{"status":"ok","timestamp":1666549359448,"user_tz":300,"elapsed":3,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["# partition into training and validation set at 80/20 division\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n","# Converting y_r and y_t into one-hot encoding using a keras utility\n","#  to_categorical\n","# The class vector to be converted into a matrix is assumed to contain\n","#  integers from 0 to num_classes. The label in iris.csv is 1, 2, 3\n","#  Hence we subtract it by 1 before conversion\n","y_train = keras.utils.to_categorical(y_train-1)\n","y_test = keras.utils.to_categorical(y_test-1)"],"id":"7501ce39","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"57fa02c9","executionInfo":{"status":"ok","timestamp":1666549359844,"user_tz":300,"elapsed":398,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["# define the keras model\n","# 4-10-10-10-3 configuration, relu and softmax activation for the \n","# hidden layer and output layer respectively\n","net = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(10, input_dim=4, activation = 'relu'),\n","    tf.keras.layers.Dense(10, activation = 'relu'),\n","    tf.keras.layers.Dense(10, activation = 'relu'),\n","    tf.keras.layers.Dense(3, activation='softmax')])"],"id":"57fa02c9","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2f08f1cb","executionInfo":{"status":"ok","timestamp":1666549359844,"user_tz":300,"elapsed":6,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["# compile the keras model\n","net.compile(loss='binary_crossentropy', optimizer='adam', \n","              metrics=['accuracy'])"],"id":"2f08f1cb","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cb0ad23a","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9859c0bd-8b8b-4850-9899-62e931d6ffe4","executionInfo":{"status":"ok","timestamp":1666549367530,"user_tz":300,"elapsed":7690,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["# fit the keras model on the dataset\n","net.fit(X_train, y_train, epochs=150, batch_size=10)"],"id":"cb0ad23a","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","12/12 [==============================] - 1s 3ms/step - loss: 0.8634 - accuracy: 0.4667\n","Epoch 2/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.7492 - accuracy: 0.3250\n","Epoch 3/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.3250\n","Epoch 4/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.3250\n","Epoch 5/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.3250\n","Epoch 6/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.3250\n","Epoch 7/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.3250\n","Epoch 8/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.3250\n","Epoch 9/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.3250\n","Epoch 10/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.3417\n","Epoch 11/150\n","12/12 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.5583\n","Epoch 12/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.6667\n","Epoch 13/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.6667\n","Epoch 14/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.6750\n","Epoch 15/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.6667\n","Epoch 16/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.6750\n","Epoch 17/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.6750\n","Epoch 18/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.6750\n","Epoch 19/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.6750\n","Epoch 20/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.6667\n","Epoch 21/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.7667\n","Epoch 22/150\n","12/12 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.7000\n","Epoch 23/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.6750\n","Epoch 24/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.7000\n","Epoch 25/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.7417\n","Epoch 26/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.7167\n","Epoch 27/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.7917\n","Epoch 28/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.7583\n","Epoch 29/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8000\n","Epoch 30/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.7750\n","Epoch 31/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.9000\n","Epoch 32/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.9250\n","Epoch 33/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8583\n","Epoch 34/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.9333\n","Epoch 35/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.9417\n","Epoch 36/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.9333\n","Epoch 37/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.9333\n","Epoch 38/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.9583\n","Epoch 39/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9500\n","Epoch 40/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9500\n","Epoch 41/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9667\n","Epoch 42/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9750\n","Epoch 43/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9417\n","Epoch 44/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9750\n","Epoch 45/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9667\n","Epoch 46/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9750\n","Epoch 47/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9667\n","Epoch 48/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9750\n","Epoch 49/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9667\n","Epoch 50/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9750\n","Epoch 51/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9667\n","Epoch 52/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9750\n","Epoch 53/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9667\n","Epoch 54/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9667\n","Epoch 55/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9667\n","Epoch 56/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9750\n","Epoch 57/150\n","12/12 [==============================] - 0s 4ms/step - loss: 0.1657 - accuracy: 0.9667\n","Epoch 58/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9833\n","Epoch 59/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9750\n","Epoch 60/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9750\n","Epoch 61/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9750\n","Epoch 62/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9750\n","Epoch 63/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9833\n","Epoch 64/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9750\n","Epoch 65/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9750\n","Epoch 66/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9750\n","Epoch 67/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9833\n","Epoch 68/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9917\n","Epoch 69/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9750\n","Epoch 70/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9667\n","Epoch 71/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9833\n","Epoch 72/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9750\n","Epoch 73/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1146 - accuracy: 0.9750\n","Epoch 74/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9750\n","Epoch 75/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9917\n","Epoch 76/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9667\n","Epoch 77/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9833\n","Epoch 78/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9917\n","Epoch 79/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9750\n","Epoch 80/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9917\n","Epoch 81/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9750\n","Epoch 82/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9917\n","Epoch 83/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9750\n","Epoch 84/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9750\n","Epoch 85/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9833\n","Epoch 86/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9750\n","Epoch 87/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9750\n","Epoch 88/150\n","12/12 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9750\n","Epoch 89/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9833\n","Epoch 90/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9833\n","Epoch 91/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9750\n","Epoch 92/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9833\n","Epoch 93/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9750\n","Epoch 94/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9750\n","Epoch 95/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9917\n","Epoch 96/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9750\n","Epoch 97/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9833\n","Epoch 98/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9917\n","Epoch 99/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9833\n","Epoch 100/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9833\n","Epoch 101/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9833\n","Epoch 102/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9833\n","Epoch 103/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9917\n","Epoch 104/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9750\n","Epoch 105/150\n","12/12 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.9833\n","Epoch 106/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9833\n","Epoch 107/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9750\n","Epoch 108/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9833\n","Epoch 109/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9917\n","Epoch 110/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9917\n","Epoch 111/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9833\n","Epoch 112/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9833\n","Epoch 113/150\n","12/12 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9750\n","Epoch 114/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9917\n","Epoch 115/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9917\n","Epoch 116/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9917\n","Epoch 117/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9917\n","Epoch 118/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9750\n","Epoch 119/150\n","12/12 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9917\n","Epoch 120/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9917\n","Epoch 121/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9750\n","Epoch 122/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9833\n","Epoch 123/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9917\n","Epoch 124/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9750\n","Epoch 125/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9833\n","Epoch 126/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9833\n","Epoch 127/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9833\n","Epoch 128/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9833\n","Epoch 129/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9833\n","Epoch 130/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9917\n","Epoch 131/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9750\n","Epoch 132/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9917\n","Epoch 133/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9917\n","Epoch 134/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9750\n","Epoch 135/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9917\n","Epoch 136/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9833\n","Epoch 137/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9833\n","Epoch 138/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9917\n","Epoch 139/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9833\n","Epoch 140/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9750\n","Epoch 141/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9833\n","Epoch 142/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9833\n","Epoch 143/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9833\n","Epoch 144/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9750\n","Epoch 145/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9833\n","Epoch 146/150\n","12/12 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9750\n","Epoch 147/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9667\n","Epoch 148/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9750\n","Epoch 149/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9917\n","Epoch 150/150\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9750\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb9b110acd0>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"3261fe2f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8864e175-b7ba-4997-bc38-98d239984175","executionInfo":{"status":"ok","timestamp":1666549367708,"user_tz":300,"elapsed":181,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["# Evaluate the trained model using keras built-in function\n","score = net.evaluate(X_test, y_test, verbose=0)\n","print(\"Test loss:\", format(score[0],\".4f\"))\n","print(\"Test accuracy:\", score[1])"],"id":"3261fe2f","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.0527\n","Test accuracy: 0.9666666388511658\n"]}]},{"cell_type":"code","metadata":{"id":"f2d65598","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6120937-e479-4f01-db49-c3a55861815a","executionInfo":{"status":"ok","timestamp":1666549367879,"user_tz":300,"elapsed":173,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["# Evaluate predicted testing output\n","# Since softmax output is used, these outputs are probability \n","# vectors of value between 0 and 1 and values of each output \n","# vector added to 1\n","y_softmax = net.predict(X_test)\n","# y_pc gives the indices (strating from 0) of the max elements\n","y_pc = np.argmax(y_softmax, axis = -1)\n","# convert y_pc into one-hot encoding\n","y_pred = keras.utils.to_categorical(y_pc)\n","\n","Cmat = tf.math.confusion_matrix(y_test.argmax(axis=-1),y_pred.argmax(axis=-1))\n","print(Cmat)"],"id":"f2d65598","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 95ms/step\n","tf.Tensor(\n","[[ 9  0  0]\n"," [ 0  9  1]\n"," [ 0  0 11]], shape=(3, 3), dtype=int32)\n"]}]},{"cell_type":"code","metadata":{"id":"aGIafJJe-V3p","executionInfo":{"status":"ok","timestamp":1666549369706,"user_tz":300,"elapsed":1829,"user":{"displayName":"YU HEN HU","userId":"04083449072545068296"}}},"source":["drive.flush_and_unmount()"],"id":"aGIafJJe-V3p","execution_count":9,"outputs":[]}]}